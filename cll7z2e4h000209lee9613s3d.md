---
title: "#Day19: Docker Volume for DevOps Engineers"
datePublished: Sat Aug 12 2023 12:07:16 GMT+0000 (Coordinated Universal Time)
cuid: cll7z2e4h000209lee9613s3d
slug: day19-docker-volume-for-devops-engineers
cover: https://cdn.hashnode.com/res/hashnode/image/upload/v1691819714349/3591d197-a53f-4d13-a7e5-33b0d2b1d91b.jpeg
tags: docker-volume, 90daysofdevops

---

🐳 **Dive into Docker Volumes and Networks!** 🚀

If you're stepping into the world of Docker, you might have heard about two cool things: **Volumes** and **Networks**. Don't worry if these sound a bit technical – I'm here to break it down for you! 🤗

### 📦 **Volumes: Your Handy Storage Spaces** 💾

Imagine you're moving into a new apartment, and you need storage for your stuff. Docker has something similar called Volumes! 🏢 These are like special storage areas that containers (those little packages that hold apps) can use.

When you run a container, it comes with its own storage space. But if that container goes away, so does its stuff! ☹️ Volumes fix this. They're like magical closets that let containers store their important data outside themselves. 🧙‍♂️

For example, think of a database. You wouldn't want to lose all your data if you accidentally delete a container, right? With Volumes, your data stays safe and sound even if the container takes a vacation. 🏖️ Plus, you can share the same volume among multiple containers. It's like having a group closet where everyone can put their things! 👥

### 🔗 **Networks: Container Hangouts for Chit-Chats** 🗣️

Now, let's talk about Docker Networks! 🌐 Imagine you have a bunch of friends, and you want them to talk to each other – that's where Networks come in.

Containers are like little worlds with their own spaces. But what if they want to chat with each other or with the computer they live on? That's where Networks set up the party! 🎉

These virtual spaces let containers connect and have conversations. It's like building bridges between their isolated lands. They can gossip, share data, and high-five each other in the virtual world! 🙌

So, think of Networks as the Wi-Fi of Docker. Just like how you connect your devices to the internet, containers can connect through Networks and have a grand old time sharing information. 📡

🔗📦 **Putting It All Together** 💡

Picture this: You have containers running different apps. Some hold databases, some run web servers, and they all want to talk to each other. With Volumes, your data is safe and sound, even if containers go on vacation. And with Networks, they can chat and share stuff like best buddies at a sleepover! 😴🎈

So there you have it – Docker's Volumes and Networks in a nutshell. It's like giving your containers superpowers to store, share, and communicate. Now you're ready to rock the Docker world like a pro! 🚢🌍

### Task-1

Create a multi-container docker-compose file which will bring UP and bring DOWN containers in a single shot ( Example - Create application and database container )

Below is an example of a `docker-compose.yml` file that sets up a multi-container application with an application container and a database container. This file will allow you to bring the containers up and down together using Docker Compose.

```plaintext
version: '3'
services:
  # Application container
  app:
    image: your-app-image:latest  # Replace with your actual app image
    ports:
      - "80:80"  # Map host port 80 to container port 80
    depends_on:
      - db  # Depends on the database container

  # Database container
  db:
    image: mysql:latest  # Example MySQL image
    environment:
      MYSQL_ROOT_PASSWORD: root_password
      MYSQL_DATABASE: mydatabase
      MYSQL_USER: app_user
      MYSQL_PASSWORD: app_password
    volumes:
      - db_data:/var/lib/mysql

volumes:
  db_data:
```

Here's what each section does:

* `services`: This section defines the services (containers) you want to run. In this case, we have an `app` container and a `db` (database) container.
    
* `app`: Configuration for the application container. You can replace `your-app-image` with the actual image you want to use. We're mapping host port 80 to container port 80, so you can access the app at [`http://localhost`](http://localhost).
    
* `db`: Configuration for the database container. We're using the MySQL image as an example. You can customize the environment variables to set up your database.
    
* `volumes`: Defines a named volume `db_data` that will persist the database data even if the containers are stopped or removed.
    

To bring the containers up and down, follow these steps:

1. Save the above content in a file named `docker-compose.yml`.
    
2. Open your terminal in the same directory as the `docker-compose.yml` file.
    
3. To start the containers in detached mode, run: `docker-compose up -d`
    
4. To view the status of the containers, run: `docker-compose ps`
    
5. To view logs for a specific service (e.g., `app`), run: `docker-compose logs app`
    
6. To scale the number of replicas for a specific service (e.g., `app`), you can use: `docker-compose up -d --scale app=3`
    
7. To bring the containers down and remove associated resources, run: `docker-compose down`
    

Remember to replace placeholders like `your-app-image`, passwords, and other configuration details with your actual values. This example gives you a starting point to create a multi-container application using Docker Compose!

### Task-2

let's dive into using Docker Volumes and Named Volumes to share files and directories between multiple containers!

**Step 1: Create a Named Volume**

Named volumes are a great way to share data between containers. Let's create a named volume:

```plaintext
docker volume create my_shared_volume
```

**Step 2: Create Containers Sharing the Volume**

Now, let's create two containers that read and write data to the same volume:

```plaintext
docker run -d --name container1 --mount source=my_shared_volume,target=/data alpine tail -f /dev/null
docker run -d --name container2 --mount source=my_shared_volume,target=/data alpine tail -f /dev/null
```

In the above commands:

* `--name` assigns a name to the container.
    
* `--mount` specifies the volume source (`my_shared_volume`) and the target path inside the container (`/data`).
    
* `alpine` is the base image we're using, and `tail -f /dev/null` keeps the container running.
    

**Step 3: Verify Shared Data**

Now, let's verify that the data is shared between the containers. We'll use the `docker exec` command to run a simple test:

```plaintext
docker exec container1 sh -c "echo 'Hello from Container 1' > /data/test.txt"
docker exec container2 cat /data/test.txt
```

You should see the output `Hello from Container 1`, confirming that data is being shared between the containers.

**Step 4: Listing and Removing the Volume**

To list all volumes:

```plaintext
docker volume ls
```

You should see `my_shared_volume` listed.

To remove the volume when you're done:

```plaintext
docker volume rm my_shared_volume
```

**Wrapping Up**

Using Docker Volumes and Named Volumes, you've successfully shared data between multiple containers. These volumes act like shared folders, making it easy for containers to communicate and collaborate. Named volumes keep your data organized and allow containers to access it even after they're stopped or removed. It's a fantastic way to make sure your data sticks around even in the dynamic world of containers! 📂🐳